{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:12:08.580587Z",
     "start_time": "2023-10-21T01:12:08.563437Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:12:08.580755Z",
     "start_time": "2023-10-21T01:12:08.564741Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:12:08.580875Z",
     "start_time": "2023-10-21T01:12:08.569281Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:12:08.580904Z",
     "start_time": "2023-10-21T01:12:08.569402Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('antoinelouis/biencoder-camembert-base-mmarcoFR')\n",
    "model = AutoModel.from_pretrained('antoinelouis/biencoder-camembert-base-mmarcoFR')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:12:10.511075Z",
     "start_time": "2023-10-21T01:12:08.571439Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:12:10.512079Z",
     "start_time": "2023-10-21T01:12:10.510205Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def get_embeddings(chunck, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Get the embedding of a passage\n",
    "    :param chunck: the passage\n",
    "    :param model: the model\n",
    "    :param tokenizer: the tokenizer\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(chunck, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    chunk_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    return chunk_embeddings.view(-1).numpy().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:12:10.518962Z",
     "start_time": "2023-10-21T01:12:10.512455Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    \"\"\"\n",
    "    To read the file\n",
    "    :param filename: string the name of the file\n",
    "    :return: string  the content of the file\n",
    "    \"\"\"\n",
    "    with open(f'judilibre_json/data/{filename}') as file:\n",
    "        content = file.read()\n",
    "    return content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:12:10.519206Z",
     "start_time": "2023-10-21T01:12:10.514697Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def split_text_into_passages(text, model, tokenizer, max_chars_per_section=128, prev_include=2):\n",
    "    \"\"\"\n",
    "    Split text into passage with maximum number of char per passage and number of char of the previous\n",
    "    passage to include in the following\n",
    "    :param text:  string the text to split\n",
    "    :param max_chars_per_section: int the max number of char per passage\n",
    "    :param prev_include: int number of char of the previous to include in the following\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    passages = []\n",
    "    current_passage = []\n",
    "    passage_ends = []\n",
    "    lines = text.splitlines()\n",
    "    for i in tqdm(range(len(lines))):\n",
    "        line = lines[i]\n",
    "        words = line.split()\n",
    "        for j, word in enumerate(words):\n",
    "            if len(\" \".join(current_passage)) + len(word) + 1 <= max_chars_per_section:\n",
    "                current_passage.append(word)\n",
    "            else:\n",
    "                passages.append(\" \".join(current_passage))\n",
    "                passage_ends.append(i + 1)\n",
    "                if prev_include > 0:\n",
    "                    current_passage = passages[-1].split()[-prev_include:]\n",
    "    if current_passage:\n",
    "        passages.append(\" \".join(current_passage))\n",
    "        passage_ends.append(len(lines))\n",
    "\n",
    "    chunks = list(range(1, len(passages) + 1))\n",
    "\n",
    "    df = pd.DataFrame({'chunck': chunks, 'line': passage_ends, 'passage': passages})\n",
    "    df['embedding'] = df['passage'].apply(lambda chunck: get_embeddings(chunck, model, tokenizer))\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:12:10.520599Z",
     "start_time": "2023-10-21T01:12:10.518421Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def get_all_tsv_file():\n",
    "    \"\"\"\n",
    "    Get the name of all data file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    path = 'judilibre_json/data'\n",
    "    tsv_files = []\n",
    "    if os.path.exists(path) and os.path.isdir(path):\n",
    "        tsv_files = [f for f in os.listdir(path) if f.endswith(\".tsv\")]\n",
    "    return tsv_files"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:12:10.522090Z",
     "start_time": "2023-10-21T01:12:10.520452Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def create_table(model, tokenizer, max_chars_per_section=128, prev_include=2):\n",
    "    all_tsv_files = get_all_tsv_file()\n",
    "    all_dfs = []\n",
    "    for i in tqdm(range(len(all_tsv_files))):\n",
    "        filename = all_tsv_files[i]\n",
    "        id_dec, _ = os.path.splitext(filename)\n",
    "        text = read_file(filename)\n",
    "        df = split_text_into_passages(text, model, tokenizer, max_chars_per_section, prev_include)\n",
    "        n_rows, _ = df.shape\n",
    "        df.insert(0, 'id_dec', [id_dec] * n_rows)\n",
    "        all_dfs.append(df)\n",
    "\n",
    "    df_judilibre_v = pd.concat(all_dfs, ignore_index=True)\n",
    "    df_judilibre_v.to_csv(f'judilibre_v/judilibre_v_{len(all_tsv_files)}.tsv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:12:10.525019Z",
     "start_time": "2023-10-21T01:12:10.523837Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]\n",
      "100%|██████████| 89/89 [00:00<00:00, 125561.07it/s]\n",
      "  3%|▎         | 1/30 [00:04<01:59,  4.11s/it]\n",
      "100%|██████████| 137/137 [00:00<00:00, 108911.99it/s]\n",
      "  7%|▋         | 2/30 [00:10<02:37,  5.63s/it]\n",
      "100%|██████████| 137/137 [00:00<00:00, 14692.02it/s]\n",
      " 10%|█         | 3/30 [00:15<02:14,  4.99s/it]\n",
      "100%|██████████| 92/92 [00:00<00:00, 131833.27it/s]\n",
      " 13%|█▎        | 4/30 [00:18<01:55,  4.46s/it]\n",
      "100%|██████████| 48/48 [00:00<00:00, 105021.70it/s]\n",
      " 17%|█▋        | 5/30 [00:20<01:30,  3.63s/it]\n",
      "100%|██████████| 115/115 [00:00<00:00, 124895.12it/s]\n",
      " 20%|██        | 6/30 [00:25<01:33,  3.90s/it]\n",
      "100%|██████████| 112/112 [00:00<00:00, 147538.33it/s]\n",
      " 23%|██▎       | 7/30 [00:29<01:30,  3.93s/it]\n",
      "100%|██████████| 56/56 [00:00<00:00, 161319.38it/s]\n",
      " 27%|██▋       | 8/30 [00:30<01:10,  3.22s/it]\n",
      "100%|██████████| 68/68 [00:00<00:00, 146638.91it/s]\n",
      " 30%|███       | 9/30 [00:33<01:02,  3.00s/it]\n",
      "100%|██████████| 186/186 [00:00<00:00, 151601.35it/s]\n",
      " 33%|███▎      | 10/30 [00:39<01:20,  4.05s/it]\n",
      "100%|██████████| 140/140 [00:00<00:00, 74946.08it/s]\n",
      " 37%|███▋      | 11/30 [00:49<01:52,  5.90s/it]\n",
      "100%|██████████| 30/30 [00:00<00:00, 261056.27it/s]\n",
      " 40%|████      | 12/30 [00:50<01:16,  4.25s/it]\n",
      "100%|██████████| 146/146 [00:00<00:00, 116508.44it/s]\n",
      " 43%|████▎     | 13/30 [00:56<01:21,  4.81s/it]\n",
      "100%|██████████| 131/131 [00:00<00:00, 136612.09it/s]\n",
      " 47%|████▋     | 14/30 [01:01<01:17,  4.83s/it]\n",
      "100%|██████████| 68/68 [00:00<00:00, 169065.01it/s]\n",
      " 50%|█████     | 15/30 [01:03<00:58,  3.92s/it]\n",
      "100%|██████████| 118/118 [00:00<00:00, 127591.61it/s]\n",
      " 53%|█████▎    | 16/30 [01:07<00:57,  4.12s/it]\n",
      "100%|██████████| 47/47 [00:00<00:00, 292047.83it/s]\n",
      " 57%|█████▋    | 17/30 [01:08<00:40,  3.10s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 120318.53it/s]\n",
      " 60%|██████    | 18/30 [01:12<00:40,  3.34s/it]\n",
      "100%|██████████| 68/68 [00:00<00:00, 111150.69it/s]\n",
      " 63%|██████▎   | 19/30 [01:15<00:35,  3.21s/it]\n",
      "100%|██████████| 82/82 [00:00<00:00, 128717.41it/s]\n",
      " 67%|██████▋   | 20/30 [01:18<00:31,  3.19s/it]\n",
      "100%|██████████| 56/56 [00:00<00:00, 184800.18it/s]\n",
      " 70%|███████   | 21/30 [01:19<00:24,  2.68s/it]\n",
      "100%|██████████| 30/30 [00:00<00:00, 34323.27it/s]\n",
      " 73%|███████▎  | 22/30 [01:24<00:26,  3.27s/it]\n",
      "100%|██████████| 60/60 [00:00<00:00, 233449.20it/s]\n",
      " 77%|███████▋  | 23/30 [01:25<00:18,  2.64s/it]\n",
      "100%|██████████| 137/137 [00:00<00:00, 124781.68it/s]\n",
      " 80%|████████  | 24/30 [01:31<00:21,  3.64s/it]\n",
      "100%|██████████| 100/100 [00:00<00:00, 130908.36it/s]\n",
      " 83%|████████▎ | 25/30 [01:35<00:18,  3.73s/it]\n",
      "100%|██████████| 39/39 [00:00<00:00, 84275.04it/s]\n",
      " 87%|████████▋ | 26/30 [01:37<00:13,  3.26s/it]\n",
      "100%|██████████| 103/103 [00:00<00:00, 150161.04it/s]\n",
      " 90%|█████████ | 27/30 [01:41<00:09,  3.29s/it]\n",
      "100%|██████████| 62/62 [00:00<00:00, 205246.13it/s]\n",
      " 93%|█████████▎| 28/30 [01:42<00:05,  2.75s/it]\n",
      "100%|██████████| 86/86 [00:00<00:00, 147048.57it/s]\n",
      " 97%|█████████▋| 29/30 [01:45<00:02,  2.79s/it]\n",
      "100%|██████████| 157/157 [00:00<00:00, 136846.58it/s]\n",
      "100%|██████████| 30/30 [01:51<00:00,  3.73s/it]\n"
     ]
    }
   ],
   "source": [
    "create_table(model, tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:14:03.543661Z",
     "start_time": "2023-10-21T01:12:10.525707Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "df = pd.read_csv('judilibre_v/judilibre_v_30.tsv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:24:36.900020Z",
     "start_time": "2023-10-21T01:24:36.364945Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "                                id_dec  chunck  line  \\\n0     JURITEXT6163873c947dd77ae6de0264       1     5   \n1     JURITEXT6163873c947dd77ae6de0264       2     8   \n2     JURITEXT6163873c947dd77ae6de0264       3    12   \n3     JURITEXT6163873c947dd77ae6de0264       4    16   \n4     JURITEXT6163873c947dd77ae6de0264       5    18   \n...                                ...     ...   ...   \n3225  JURITEXT63ff0297002ac605de15b669     182   154   \n3226  JURITEXT63ff0297002ac605de15b669     183   155   \n3227  JURITEXT63ff0297002ac605de15b669     184   156   \n3228  JURITEXT63ff0297002ac605de15b669     185   156   \n3229  JURITEXT63ff0297002ac605de15b669     186   157   \n\n                                                passage  \\\n0     Grosses délivrées REPUBLIQUE FRANCAISE aux par...   \n1     4 ARRET 16 FEVRIER 2011 (n° 54, 5 pages) Numér...   \n2     Cour : du 15 Avril 2009 Tribunal de Commerce d...   \n3     poursuites et de son représentant légal [Adres...   \n4     Cour assistée Me LE ROC'H Armelle, avocat au b...   \n...                                                 ...   \n3225  le fondement l'article 700 du code de procédur...   \n3226  dépens en d'appel. Prononcé publiquement par m...   \n3227  ayant été avisées dans les conditions prévues ...   \n3228  par Madame Charbonnier, Conseillère faisant fo...   \n3229  qui la de la décision a été remise par la magi...   \n\n                                              embedding  \n0     [0.19662752747535706, 0.1327817291021347, -0.1...  \n1     [0.002567474963143468, 0.2334602177143097, -0....  \n2     [-0.049415867775678635, -0.13155849277973175, ...  \n3     [0.04500657320022583, 0.02714894898235798, 0.2...  \n4     [-0.03509717434644699, 0.0044215163215994835, ...  \n...                                                 ...  \n3225  [-0.08968550711870193, 0.11280424892902374, 0....  \n3226  [-0.08342866599559784, -0.1942174732685089, -0...  \n3227  [0.09881575405597687, 0.22274042665958405, -0....  \n3228  [0.10842771083116531, 0.048915620893239975, 0....  \n3229  [0.019627941772341728, -0.02314232476055622, -...  \n\n[3230 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_dec</th>\n      <th>chunck</th>\n      <th>line</th>\n      <th>passage</th>\n      <th>embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>JURITEXT6163873c947dd77ae6de0264</td>\n      <td>1</td>\n      <td>5</td>\n      <td>Grosses délivrées REPUBLIQUE FRANCAISE aux par...</td>\n      <td>[0.19662752747535706, 0.1327817291021347, -0.1...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>JURITEXT6163873c947dd77ae6de0264</td>\n      <td>2</td>\n      <td>8</td>\n      <td>4 ARRET 16 FEVRIER 2011 (n° 54, 5 pages) Numér...</td>\n      <td>[0.002567474963143468, 0.2334602177143097, -0....</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>JURITEXT6163873c947dd77ae6de0264</td>\n      <td>3</td>\n      <td>12</td>\n      <td>Cour : du 15 Avril 2009 Tribunal de Commerce d...</td>\n      <td>[-0.049415867775678635, -0.13155849277973175, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>JURITEXT6163873c947dd77ae6de0264</td>\n      <td>4</td>\n      <td>16</td>\n      <td>poursuites et de son représentant légal [Adres...</td>\n      <td>[0.04500657320022583, 0.02714894898235798, 0.2...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>JURITEXT6163873c947dd77ae6de0264</td>\n      <td>5</td>\n      <td>18</td>\n      <td>Cour assistée Me LE ROC'H Armelle, avocat au b...</td>\n      <td>[-0.03509717434644699, 0.0044215163215994835, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3225</th>\n      <td>JURITEXT63ff0297002ac605de15b669</td>\n      <td>182</td>\n      <td>154</td>\n      <td>le fondement l'article 700 du code de procédur...</td>\n      <td>[-0.08968550711870193, 0.11280424892902374, 0....</td>\n    </tr>\n    <tr>\n      <th>3226</th>\n      <td>JURITEXT63ff0297002ac605de15b669</td>\n      <td>183</td>\n      <td>155</td>\n      <td>dépens en d'appel. Prononcé publiquement par m...</td>\n      <td>[-0.08342866599559784, -0.1942174732685089, -0...</td>\n    </tr>\n    <tr>\n      <th>3227</th>\n      <td>JURITEXT63ff0297002ac605de15b669</td>\n      <td>184</td>\n      <td>156</td>\n      <td>ayant été avisées dans les conditions prévues ...</td>\n      <td>[0.09881575405597687, 0.22274042665958405, -0....</td>\n    </tr>\n    <tr>\n      <th>3228</th>\n      <td>JURITEXT63ff0297002ac605de15b669</td>\n      <td>185</td>\n      <td>156</td>\n      <td>par Madame Charbonnier, Conseillère faisant fo...</td>\n      <td>[0.10842771083116531, 0.048915620893239975, 0....</td>\n    </tr>\n    <tr>\n      <th>3229</th>\n      <td>JURITEXT63ff0297002ac605de15b669</td>\n      <td>186</td>\n      <td>157</td>\n      <td>qui la de la décision a été remise par la magi...</td>\n      <td>[0.019627941772341728, -0.02314232476055622, -...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3230 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:24:38.580518Z",
     "start_time": "2023-10-21T01:24:38.568024Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
